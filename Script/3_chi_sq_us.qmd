---
title: "3_chi_sq_us"
author: "Maiko Hata"
format: pdf
execute: 
  eval: true 
editor: visual
engine: knitr
---

```{r}
library(tidyverse)
library(here)
library(rio)
library(knitr)
library(gt)
library(DT)
library(reactable)
library(gtsummary)
library(kableExtra)
library(tinytex)
library(janitor)
library(tidylog)
library(sjPlot)
library(lme4)
library(tibble)
library(dplyr)
library(epitools)
library(readxl)
library(pwr)
library(rcompanion)
library(grateful)
library(distill)
library(readxl)
library(scales)
library(tidyr)
library(patchwork)
library(corrplot)
library(distill)
library(tibble)
library(rcartocolor)
library(ggplot2)
library(quarto)
library(descr)
```

#### Chi-Square for all the races and all the exit reasons

```{r}
race_us_2 <- read_csv("/Users/hata/Desktop/EDLD652_Diss/Data/race_us.csv")
```

```{r}
print(race_us_2)
colnames(race_us_2)
```

```{r}
chi_omni_2 <-chisq.test(race_us_2[, 4:9])
```

```{r}
print(chi_omni_2)
```

#### Chi-square with residuals for all the races and all the exit reasons

```{r}
# Step 1: Extract just the matrix of counts for exit reasons
chi_matrix_2 <- as.matrix(race_us_2[, 4:9])
```

```{r}
# Step 2: Run chi-square test
chi_result_2 <- chisq.test(race_us_2[, 4:9])
```

```{r}
# Step 3: Extract standardized residuals
stdres_2 <- chi_result_2$stdres
```

```{r}
# Step 4: Convert standardized residuals matrix to a tidy data frame
library(tibble)

stdres_df_2 <- as.data.frame(stdres_2)
stdres_df_2 <- rownames_to_column(stdres_df_2, var = "Race")
```

```{r}
# Select only the exit reason columns (columns 4 to 9)
race_us_2_matrix <- as.matrix(race_us_2[, 4:9])
```

```{r}
# Run the chi-square test
chi_test_2 <- chisq.test(race_us_2_matrix)

# Extract standardized residuals
stdres_matrix_2 <- chi_test_2$stdres
```

```{r}
stdres_matrix_2
```

```{r}
# Set readable row names (races)
rownames(stdres_matrix_2) <- c(
  "AI/AN", "Asian", "Black", "Hispanic", "Two+ Races", "NH/PI", "White"
)

# Set readable column names (exit reasons)
colnames(stdres_matrix_2) <- c(
  "Withdrawn", "Dismissed", "Moved Out", 
  "Part B Eligible", "Not Eligible", "Not Determined"
)

```

```{r}
# Alphabetize both race categories (rows) and exit reasons (columns)
stdres_matrix_2 <- stdres_matrix_2[
  order(rownames(stdres_matrix_2)), 
  order(colnames(stdres_matrix_2))
]

```

```{r}
kable(stdres_matrix_2)
```

```{r}

kable(stdres_matrix_2, digits = 2) %>%
  kable_styling(
    full_width = FALSE,
    position = "center",
    font_size = 12
  ) %>%
  kable_classic(html_font = "Cambria", full_width = FALSE) %>%
  column_spec(1:ncol(stdres_matrix_2), extra_css = "text-align: center;") %>%
  row_spec(0, bold = TRUE)
```

```{r}
### 6/18/25 --- saving it as csv so that I can modify it on the docs 

# Convert matrix to data frame with Race as a column
stdres_df_rounded <- as.data.frame(stdres_matrix_2) %>%
  rownames_to_column(var = "Race") %>%
  mutate(across(where(is.numeric), ~ round(.x, 2)))

# Write to CSV
write.csv(stdres_df_rounded, 
          file = "/Users/hata/Desktop/EDLD652_Diss/Data/stdres_matrix_2.csv", 
          row.names = FALSE)

```

#### 6/12/25: Checking to see if I can run corrplot() on stdres_matrix_2

```{r}
### In 3_chi_sq_qmd, I'm running corrplot like this with chi_results$stdres, I should be able to with stdres_matrix_2, no? 
library(corrplot)

```

```{r}
corrplot(stdres_matrix_2,
         is.cor = FALSE,        # This tells it you're plotting non-correlation data
         tl.cex = 0.8,
         tl.col = "black",
         cl.cex = 0.7,
         cl.offset = 1,
         cl.ratio = 0.2)

```

```{r}
# corrplot(stdres_matrix_2,
#          is.cor = FALSE,
#          method = "number",
#          number.cex = 0.7,      # Smaller text inside the cells
#          tl.cex = 0.8,          # Axis label size
#          tl.col = "black",
#          cl.cex = 0.7,
#          cl.offset = 1,
#          cl.ratio = 0.2)

```

#### Odds ratio for each racial group to be dismissed, compared to the national average.

```{r}
colnames(race_us_2)
```

```{r}
colnames(race_us_2) <- c(
  "Race",
  "area",
  "Total Exits",
  "Withdrawn",
  "Dismissed",
  "Moved Out",
  "Part B Eligible",
  "Not Eligible",
  "Not Determined"
)

```

```{r}
write.csv(race_us_2, file = "/Users/hata/Desktop/EDLD652_Diss/Data/race_us_2.csv", row.names = FALSE)
```

```{r}
# Ensure all exit columns are numeric (except Total Exit, which we ignore)
exit_cols <- c("Withdrawn", "Dismissed", "Moved Out", 
               "Part B Eligible", "Not Eligible", "Not Determined")

# Subset the data to just the exit counts
exit_data <- race_us_2[, c("Race", exit_cols)]

```

```{r}
# Step 1: Rename columns for clarity
colnames(race_us_2) <- c(
  "Race", "Area", "Total Exit", "Withdrawn", "Dismissed",
  "Moved Out", "Part B Eligible", "Not Eligible", "Not Determined"
)

```

```{r}
# Step 2: Deleted because it was redundant (dropping a column)
```

```{r}
# Step 3 (Revised): Clean and rename the dataset to prepare for odds ratio analysis

race_us_2 <- race_us_2 %>%
  select(-`Total Exit`, -`Area`) %>%  # ✅ Corrected column names
  rename(
    `Withdrawn` = `Withdrawn`,
    `Dismissed` = `Dismissed`,
    `Moved Out` = `Moved Out`,
    `Part B Eligible` = `Part B Eligible`,
    `Not Eligible` = `Not Eligible`,
    `Not Determined` = `Not Determined`
  )

library(dplyr)

# ✅ Step 3 continued: Convert all exit count columns to numeric (except Race)
race_us_2 <- race_us_2 %>%
  mutate(across(-Race, ~ as.numeric(gsub(",", "", .))))

```

```{r}
# ✅ Step 4: Define the odds ratio function for Dismissed exits (clean and CI-ready)

get_dismissed_or <- function(group) {
  df <- race_us_2 %>%
    mutate(
      Dismissed = as.numeric(Dismissed),
      Total = rowSums(across(c(`Withdrawn`, `Dismissed`, `Moved Out`, 
                                `Part B Eligible`, `Not Eligible`, `Not Determined`)), na.rm = TRUE)
    )
  
  # Step 4.1: Group of interest (target group)
  a <- df %>% filter(Race == group) %>% pull(Dismissed)
  b <- df %>% filter(Race == group) %>% pull(Total) - a
  
  # Step 4.2: All other groups (everyone except target group)
  c <- df %>% filter(Race != group) %>% summarise(sum(Dismissed, na.rm = TRUE)) %>% pull()
  d <- df %>% filter(Race != group) %>% summarise(sum(Total, na.rm = TRUE)) %>% pull() - c
  
  # Step 4.3: Construct 2x2 matrix and run chi-square test
  mat <- matrix(c(a, b, c, d), nrow = 2, byrow = TRUE)
  result <- chisq.test(mat)
  
  # Step 4.4: Manually compute odds ratio and 95% confidence interval
  or <- (a / b) / (c / d)
  se_log_or <- sqrt(1 / a + 1 / b + 1 / c + 1 / d)
  ci_lower <- exp(log(or) - 1.96 * se_log_or)
  ci_upper <- exp(log(or) + 1.96 * se_log_or)
  
  # Step 4.5: Return a tibble with the OR, CI, and p-value
  tibble(
    `Odds Ratio` = or,
    `P Value` = result$p.value,
    Lower = ci_lower,
    Upper = ci_upper
  )
}

```

```{r}
# Step 5: Apply the function to compute odds ratios for all race groups

# Step 5.1: Get the list of unique race categories
race_list <- unique(race_us_2$Race)

# Step 5.2: Use purrr::map to apply get_dismissed_odds to each race
library(purrr)

dismissed_odds_results <- map(race_list, get_dismissed_or)

# Step 5.3: Name the list elements by race for easy reference
names(dismissed_odds_results) <- race_list


```

```{r}
# # Step 6.1: Extract the key results from each test
summary_df_odds_dismissed <- bind_rows(dismissed_odds_results, .id = "Race")

```

```{r}
summary_df_odds_dismissed

```

```{r}
str(dismissed_odds_results)
```

```{r}
# ✅ Step 6.2: Round the values for readability
summary_df_odds_dismissed <- summary_df_odds_dismissed %>%
  mutate(
    `Odds Ratio` = round(`Odds Ratio`, 2),
    Lower = round(Lower, 2),
    Upper = round(Upper, 2),
    `P Value` = ifelse(`P Value` < .001, "< .001", round(`P Value`, 3))
  )

```

```{r}
# Step 6.3: Move "National Average" to the bottom explicitly
summary_df_odds_dismissed <- summary_df_odds_dismissed %>%
  mutate(Race = ifelse(Race == "National Average", "zzz_National Average", Race)) %>%
  arrange(Race) %>%
  mutate(Race = ifelse(Race == "zzz_National Average", "National Average", Race))
```

```{r}
colnames(summary_df_odds_dismissed)
```

```{r}
# Step 6.4: 
summary_df_odds_dismissed <- summary_df_odds_dismissed %>%
  mutate(
    `Odds Ratio` = round(`Odds Ratio`, 2),
    Lower = round(Lower, 2),
    Upper = round(Upper, 2),
    `P Value` = ifelse(`P Value` < .001, "< .001", round(`P Value`, 3))
  )

```

```{r}
# Step 6.5: Reorder so National Average is last
summary_df_odds_dismissed <- summary_df_odds_dismissed %>%
  mutate(Race = ifelse(Race == "National Average", "zzz_National Average", Race)) %>%
  arrange(Race) %>%
  mutate(Race = ifelse(Race == "zzz_National Average", "National Average", Race))
```

```{r}
# Add National Average row manually
national_row <- tibble(
  Race = "National Average",
  `Odds Ratio` = 1.00,
  `P Value` = NA  # or use "." or "< .001" if you prefer
)

summary_df_odds_dismissed <- bind_rows(summary_df_odds_dismissed, national_row)
```

```{r}
# Step 6.6: Display table
### DOESN'T RUN, BUT I DON'T NEED IT SO LET's LEAVE IT FOR NOW... 
kable(summary_df_odds_dismissed, align = "lcc") %>%
  kable_styling(full_width = FALSE, position = "center") %>%
  kable_classic(full_width = FALSE, html_font = "Cambria")
```

#### Calculate cohen's h

```{r}
# Step 1: Load necessary libraries
library(dplyr)
library(knitr)
library(kableExtra)

# Step 2: Define Cohen's h function
compute_cohens_h <- function(p1, p2) {
  2 * asin(sqrt(p1)) - 2 * asin(sqrt(p2))
}

# Step 3: Read and prepare the data from original file (includes Total Exit)
race_us_2_clean2 <- read.csv("/Users/hata/Desktop/EDLD652_Diss/Data/race_us.csv")

# Step 4: Rename columns properly
colnames(race_us_2_clean2) <- c(
  "Race", "Area", "Total Exit", "Withdrawn", "Dismissed",
  "Moved Out", "Part B Eligible", "Not Eligible", "Not Determined"
)

# Step 5: Compute totals and proportions
race_us_2_clean2 <- race_us_2_clean2 %>%
  mutate(
    Dismissed = as.numeric(Dismissed),
    Total = as.numeric(`Total Exit`),
    Proportion = Dismissed / Total
  )

# Step 6: Compute national dismissal rate
national_dismissed <- sum(race_us_2_clean2$Dismissed, na.rm = TRUE)
national_total <- sum(race_us_2_clean2$Total, na.rm = TRUE)
national_rate <- national_dismissed / national_total

# Step 7: Compute Cohen’s h
summary_df_h_dismissed <- race_us_2_clean2 %>%
  mutate(
    `National Avg` = national_rate,
    `Cohen's h` = round(compute_cohens_h(Proportion, national_rate), 3)
  ) %>%
  select(
    Race,
    `Dismissed N` = Dismissed,
    `Total N` = Total,
    `Dismissed %` = Proportion,
    `National Avg %` = `National Avg`,
    `Cohen's h`
  ) %>%
  mutate(
    `Dismissed %` = sprintf("%.2f%%", 100 * `Dismissed %`),
    `National Avg %` = sprintf("%.2f%%", 100 * `National Avg %`)
  )

# Step 8: Display with kable
kable(summary_df_h_dismissed, caption = "Cohen's h for 'Dismissed' Exit Rates by Race") %>%
  kable_styling(full_width = FALSE, position = "center") %>%
  kable_classic(full_width = FALSE, html_font = "Cambria")

```

#### Forrest Plot for Odds ratio

```{r}
# ✅ Step 1: Modify the get_dismissed_or() function to return CIs

# get_dismissed_or <- function(group) {
#   a <- race_us_2_clean %>% filter(Race == group) %>% pull(Dismissed)
#   b <- race_us_2_clean %>% filter(Race == group) %>% pull(Total) - a
#   c <- race_us_2_clean %>% filter(Race != group) %>% summarise(sum(Dismissed)) %>% pull()
#   d <- race_us_2_clean %>% filter(Race != group) %>% summarise(sum(Total)) %>% pull() - c
#   
#   mat <- matrix(c(a, b, c, d), nrow = 2, byrow = TRUE)
#   result <- stats::fisher.test(mat)
#   
#   tibble(
#     `Odds Ratio` = result$estimate,
#     `P Value` = result$p.value,
#     Lower = result$conf.int[1],
#     Upper = result$conf.int[2]
#   )
# }

```

```{r}
# ✅ Step 2: Apply it to all racial groups (excluding national average for now)
# 
# 
# races <- race_us_2_clean$Race
# 
# summary_df <- map_dfr(races, function(race) {
#   get_dismissed_or(race) %>%
#     mutate(Race = race)
# })

```

```{r}
# ✅ Step 3: Add the National Average row (optional, with NA CI)
# summary_df <- summary_df %>%
#   bind_rows(tibble(
#     Race = "National Average",
#     `Odds Ratio` = 1,
#     `P Value` = NA,
#     Lower = NA,
#     Upper = NA
#   ))

```

```{r}
# ✅ Step 4: Clean and prepare for forest plot

# summary_df <- summary_df %>%
#   mutate(
#     `Odds Ratio` = round(`Odds Ratio`, 2),
#     Lower = round(Lower, 2),
#     Upper = round(Upper, 2),
#     `P Value` = ifelse(`P Value` < .001, "< .001", round(`P Value`, 3))
#   )

```

```{r}
# ✅ Step 5: Make Race a factor so National Average is last
# summary_df$Race <- factor(summary_df$Race, levels = c(
#   setdiff(summary_df$Race, "National Average"), "National Average"
# ))

```

```{r}
# # Reverse order: top = A, bottom = Z (with National Average last)
summary_df_odds_dismissed$Race <- factor(
  summary_df_odds_dismissed$Race,
  levels = rev(c(sort(setdiff(summary_df_odds_dismissed$Race, "National Average")), "National Average"))
)


```

```{r}

ggplot(summary_df_odds_dismissed, aes(x = `Odds Ratio`, y = Race)) +
  geom_point(color = "skyblue", size = 4) +
  geom_errorbarh(aes(xmin = Lower, xmax = Upper), height = 0.2) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "green") +
  geom_text(aes(label = sprintf("%.2f", `Odds Ratio`)), vjust = -1.2, size = 3.5) +
  scale_x_log10() +
  labs(
    x = "Odds Ratio (log scale)",
    y = ""
  ) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 12),
    axis.text.x = element_text(size = 12),
    plot.title = element_text(size = 14, face = "bold")
  )

```
