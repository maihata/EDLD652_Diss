---
title: "1_clean_data"
author: "Maiko Hata"
format: 
  pdf:
    mainfont: "Times New Roman"
    sansfont: "Times New Roman"
fig-width: 7
fig-height: 4
csl: apa.csl
execute: 
  eval: true 
  echo: false
  message: false 
  warning: false
editor: visual
engine: knitr
---

```{r}
#| label: library group

library(tidyverse)
library(here)
library(rio)
library(knitr)
library(gt)
library(DT)
library(reactable)
library(gtsummary)
library(kableExtra)
library(tinytex)
library(janitor)
library(tidylog)
library(sjPlot)
library(lme4)
library(tibble)
library(dplyr)
library(epitools)
library(readxl)
library(pwr)
library(rcompanion)
library(grateful)
library(distill)
library(readxl)
library(scales)
library(tidyr)
library(patchwork)
library(corrplot)
library(distill)
library(tibble)
library(rcartocolor)
library(ggplot2)
library(quarto)
```

### csv1: 10 exit categories

(for Kable table)

```{r}
exit_categories <- import(here("Data","exit_categories.xlsx")) %>%
 clean_names() 
```

```{r}
write.csv(exit_categories, 
          file = "/Users/hata/Desktop/EDLD652_Diss/Data/exit_categories.csv", 
          row.names = FALSE)
```

### csv2: byrace

(imported OSEP excel, 2013-22, US/OR, deceased/continuing in Part C removed, mutated complete_or_not_eligible to combine 3 similar categories)

```{r include=FALSE}
#|label: load-data
# importing the data and cleaning it up

byrace <- import(here("Data", "race v.2.xlsx")) %>% 
  clean_names() %>% 
  select(-7, -12) %>% 
  mutate(
    complete_or_not_eligible = 
      complete_prior_to_reaching_max_age_for_part_c + 
      not_eligible_for_part_b_exit_with_no_referrals + 
      not_eligible_for_part_b_exit_with_referrals_to_other_programs)
```

```{r}
write.csv(byrace, 
          file = "/Users/hata/Desktop/EDLD652_Diss/Data/byrace.csv", 
          row.names = FALSE)
```

### csv3: agg_by_race_and_state

based on "byrace", dropped the combined 3 categories, so just total + 6 exit categories

```{r}
#| label: aggregated-by-race

# aggregated by race and state
agg_by_race_and_state <- byrace %>% 
  group_by(race, area) %>% 
  summarize(exit_total = sum(exiting_total2), 
            withdrawal_by_parent = sum(withdrawal_by_parent),
            attempts_to_contact_unsuccessful = sum(attempts_to_contact_unsuccessful),
            moved_out_of_state = sum(moved_out_of_state),
            part_b_eligible_exiting_part_c = sum(part_b_eligible_exiting_part_c),
            complete_or_not_eligible = sum(complete_or_not_eligible), 
            part_b_eligibility_not_determined = sum(part_b_eligibility_not_determined))
```

```{r}
write.csv(agg_by_race_and_state, 
          file = "/Users/hata/Desktop/EDLD652_Diss/Data/agg_by_race_and_state.csv", 
          row.names = FALSE)
```

### csv 4: race_oregon

based on agg_by_race_and_state but Oregon only

```{r}
race_oregon <- agg_by_race_and_state %>%
  filter(area == "Oregon")
```

```{r}
write.csv(race_oregon, 
          file = "/Users/hata/Desktop/EDLD652_Diss/Data/race_oregon.csv", 
          row.names = FALSE)
```

### csv 5: race_us

```{r}
# aggregated by race for US
race_us <- agg_by_race_and_state %>% 
  filter(area == "US and Outlying Areas")
```

```{r}
write.csv(race_us, 
          file = "/Users/hata/Desktop/EDLD652_Diss/Data/race_us.csv", 
          row.names = FALSE)
```

### csv 6: race_us_chart

US Exit reasons by race (deleted "area")

```{r}
race_us_chart <-race_us %>% 
  select(-"area")
```

```{r}
# removed exit_total first, readding it, effectively moving exit total to the last column 
race_us_chart <- race_us %>% 
  select(-area, everything(), -exit_total, exit_total)
```

```{r}
colnames(race_us_chart)
```

```{r}
race_us_chart <- race_us_chart %>% 
  rename(
    "Race" = race, 
    "Withdrawn" = withdrawal_by_parent, 
   "Disqualified" = attempts_to_contact_unsuccessful, 
"Moved Out" = moved_out_of_state, 
    "Part B Eligible" = part_b_eligible_exiting_part_c, 
    "Not Eligible" = complete_or_not_eligible, 
    "Not Determined" = part_b_eligibility_not_determined, 
  )
```

```{r}
race_us_chart <- race_us_chart %>% 
  select("Race", sort(setdiff(names(.), "Race")))
```

```{r}
race_us_chart <- race_us_chart %>% 
  select(-2, -4) 
```

```{r}
write.csv(race_us_chart, 
          file = "/Users/hata/Desktop/EDLD652_Diss/Data/race_us_chart.csv", 
          row.names = FALSE)
```

### csv 7: race_oregon_chart

Oregon Exit reasons by race chart

```{r}
race_oregon_chart <-race_oregon %>% 
  select(-"area")
```

```{r}
# removed exit_total first, readding it, effectively moving exit total to the last column 
race_oregon_chart <- race_oregon_chart %>% 
  select(everything(), -exit_total, exit_total)
```

```{r}
race_oregon_chart <- race_oregon_chart %>% 
  rename(
    "Race" = race, 
    "Withdrawn" = withdrawal_by_parent, 
   "Disqualified" = attempts_to_contact_unsuccessful, 
"Moved Out" = moved_out_of_state, 
    "Part B Eligible" = part_b_eligible_exiting_part_c, 
    "Not Eligible" = complete_or_not_eligible, 
    "Not Determined" = part_b_eligibility_not_determined, 
  )
```

```{r}
race_oregon_chart <- race_oregon_chart %>% 
  select("Race", sort(setdiff(names(.), "Race")))
```

```{r}
write.csv(race_oregon_chart, 
          file = "/Users/hata/Desktop/EDLD652_Diss/Data/race_oregon_chart.csv", 
          row.names = FALSE)
```

### csv 8: area_by_race & other_by_race

--- df w. % of each racial group represented in the EI exit total data for OREGON and NATIONAL

```{r}
area_by_race <- byrace %>% 
  group_by(race) %>% 
  summarize(
    total_exit = sum(exiting_total2),
    .groups = "drop") %>% 
  mutate(percentage = round(total_exit/sum(total_exit),
                            digits = 4)*100)
```

```{r}
write.csv(area_by_race, file = "/Users/hata/Desktop/EDLD652_Diss/Data/area_by_race.csv", 
          row.names = FALSE)
```

### csv 9: other_by_race

--- same as csv 8, but for NATIONAL data, filtered by US and Outlying Areas

```{r}
other_by_race <- byrace %>% 
  filter(area == "US and Outlying Areas") %>% 
  group_by(race) %>% 
  summarize(
    total_exit = sum(exiting_total2),
    .groups = "drop"
    ) %>% 
  mutate(percentage = round(total_exit/sum(total_exit), digits = 3)*100)
```

```{r}
write.csv(area_by_race, file = "/Users/hata/Desktop/EDLD652_Diss/Data/area_by_race.csv", 
          row.names = FALSE)
```

### csv 10: oregon_by_race

```{r}
oregon_by_race <- byrace %>% 
  filter(area == "Oregon") %>% 
  group_by(race) %>% 
  summarize(
    total_exit = sum(exiting_total2),
    .groups = "drop" # .groups = drop: All levels of grouping are dropped.
  ) %>% 
  mutate(percentage = round(total_exit/sum(total_exit), digits = 3)*100)

```

```{r}
write.csv(oregon_by_race, file = "/Users/hata/Desktop/EDLD652_Diss/Data/oregon_by_race.csv", 
          row.names = FALSE)
```

```{r}
# We were curious if PI's (Pacific Islanders) small numbers skewed the chi-square, so we took it out and ran it again. It doesn't seem to have impacted much as P value is still very small with or without PI data. 

race_oregon_subset <- race_oregon %>% 
  filter(race != "PI")

# chisq.test(race_oregon_subset[, 3:8])
```

### csv 11a & 11b: us_data_long & us_data_wide

```{r}
us_data_long <- race_us %>% 
  pivot_longer(
    cols = 4:8,
    values_to = "values",
    names_to = "names"
  ) %>% 
  group_by(race) %>% 
  mutate(percentage = round(values/exit_total, digits = 4)) 
```

```{r}
write.csv(us_data_long, file = "/Users/hata/Desktop/EDLD652_Diss/Data/us_data_long.csv", 
          row.names = FALSE)
```

wide

```{r}
us_data_wide <- us_data_long %>% 
  select(-c(exit_total,values)) %>% 
  pivot_wider(
    names_from = names,
    values_from = percentage
  )
```

```{r}
write.csv(us_data_wide, file = "/Users/hata/Desktop/EDLD652_Diss/Data/us_data_wide.csv", 
          row.names = FALSE)
```

### csv 12: agg_by_area

--- TOTAL EXITS vs WITHDRAWAL in OREGON and US but NO RACE so not too meaningful, so I didn't save as CSV

```{r}
agg_by_area <- byrace %>% 
  group_by(area) %>% 
  summarize(exit_total = sum(exiting_total2), 
            withdrawal_by_parent = sum(withdrawal_by_parent))
```

```{r}
write.csv(agg_by_area, file = "/Users/hata/Desktop/EDLD652_Diss/Data/agg_by_area.csv",
          row.names = FALSE)
```

```{r}
data_oregon <- byrace %>% 
  filter(area == "Oregon") %>% 
  group_by(race) %>% 
  summarize(exit_total = sum(exiting_total2), 
            withdrawal_by_parent = sum(withdrawal_by_parent)) %>% 
  mutate(proportion = withdrawal_by_parent / exit_total)

# chi square for oregon 
# chisq.test(data_oregon[, 2:3])
```

```{r}
write.csv(data_oregon, file = "/Users/hata/Desktop/EDLD652_Diss/Data/data_oregon.csv", row.names = FALSE)
```

### csv 13: data_national (exit vs withdrawn)

--- national data comparing TOTAL EXITS vs WITHDRAWAL by RACE

```{r}
data_national <- byrace %>% 
  filter(area == "US and Outlying Areas") %>% 
  group_by(race) %>% 
  summarize(exit_total = sum(exiting_total2), 
            withdrawal_by_parent = sum(withdrawal_by_parent)) %>% 
  mutate(proportion = withdrawal_by_parent / exit_total) 
```

```{r}
write.csv(data_national, file = "/Users/hata/Desktop/EDLD652_Diss/Data/data_national.csv",row.names = FALSE)
```

```{r}
# remaking a df with exit total and DQ 12/1
us_data_attempts <- byrace %>% 
  filter(area == "US and Outlying Areas") %>% 
  group_by(race) %>% 
  summarize(exit_total = sum(exiting_total2), 
            attempts_to_contact_unsuccessful = sum(attempts_to_contact_unsuccessful)) %>% 
  mutate(proportion = attempts_to_contact_unsuccessful / exit_total)

```

```{r}
write.csv(us_data_attempts, file = "/Users/hata/Desktop/EDLD652_Diss/Data/us_data_attempts.csv",row.names = FALSE)
```

### csv 14: us_data_attempts_BLWH 

--- DQ for BLACK and WHITE for chi-square and odds ratio

```{r}
# 12/1 DQ chi-square prep continues SUCCESS!! :) 
us_data_attempts_BLWH <- us_data_attempts %>% 
  select(race, exit_total, attempts_to_contact_unsuccessful) %>% 
filter(race == "BL" | race == "WH") 
```

```{r}
write.csv(us_data_attempts_BLWH, file = "/Users/hata/Desktop/EDLD652_Diss/Data/us_data_attempts_BLWH.csv", 
          row.names = FALSE)
```

### csv 15: oregon_data_long & oregon_data_long

```{r}
# Oregon data long and wide
oregon_data_long <- race_oregon %>% 
  pivot_longer(
  cols = 4:8,
  values_to = "values",
  names_to = "names"
 ) %>% 
  group_by(race) %>% 
  mutate(percentage = round(values/exit_total, digits = 4))
```

```{r}
write.csv(oregon_data_long, file = "/Users/hata/Desktop/EDLD652_Diss/Data/oregon_data_long.csv", 
          row.names = FALSE)
```

wide

```{r}
oregon_data_wide <- oregon_data_long %>% 
  select(-c(exit_total,values)) %>% 
  pivot_wider(
    names_from = names,
    values_from = percentage
  )
```

```{r}
write.csv(oregon_data_wide, file = "/Users/hata/Desktop/EDLD652_Diss/Data/oregon_data_wide.csv", 
          row.names = FALSE)
```

### csv 16: oregon_data_wide_DQ

```{r}
# figure 2 for Oregon DQ data 
oregon_data_wide_DQ <- oregon_data_wide %>% 
  select(race, attempts_to_contact_unsuccessful) %>%  
  mutate(
    attempts_to_contact_unsuccessful = attempts_to_contact_unsuccessful * 100
  )
```

```{r}
write.csv(oregon_data_wide_DQ, file = "/Users/hata/Desktop/EDLD652_Diss/Data/oregon_data_wide_DQ.csv")
```

### csv 17: us_data_DQ 

--- Very similar to us_data_attempts_BLWH which has more data, us_data_DQ only has BLACK/WHITE DQs, saved for chi-square —

```{r}
# Did I just make the summary table of what we decided to look at for this project!?!? Okay I did the same work again but that's okay, GAH 
# WE STILL HAVE TO FILTER ONLY BL AND WHITE BEFORE RUNNING THE CHI SQUARE 
# us_data_DQ <- byrace %>% 
#  filter(area == "US and Outlying Areas") %>% 
#  group_by(race) %>% 
#  summarize(exit_total = sum(exiting_total2), 
#            attempts_to_contact_unsuccessful = 
# sum(attempts_to_contact_unsuccessful))

# Filtered BL and WH - 1202
# Is the chisq_test correct? Need to check this

us_data_DQ <- byrace %>%
 filter(area == "US and Outlying Areas", race %in% c("BL", "WH")) %>%
 group_by(race) %>%
 summarize(exit_total = sum(exiting_total2),
           attempts_to_contact_unsuccessful =
sum(attempts_to_contact_unsuccessful))

```

```{r}
write.csv(us_data_DQ, file = "/Users/hata/Desktop/EDLD652_Diss/Data/us_data_DQ.csv")
```

### csv 18: us_data_DQ_proportion 

--- df for making the plot 2 —-

```{r}
# Used this dataset for making the figure 2
us_data_DQ_proportion <- byrace %>% 
  filter(area == "US and Outlying Areas") %>% 
  group_by(race) %>% 
  summarize(exit_total = sum(exiting_total2), 
            attempts_to_contact_unsuccessful = sum(attempts_to_contact_unsuccessful)) %>% 
  mutate(proportion = (attempts_to_contact_unsuccessful / exit_total) * 100) 
```

# CLEAND UP TO HERE

The chi-square indicated that there was a statistically significant association between children being Black/African American or White and them leaving EI due to being disqualified nationally. The chi-square test indicated, X-squared (222556.00, N = 2,088,058), *p* \< 2.2e-16 or 0.0000000000000002 (*p* \< .001).

```{r}
# prepping the df to mutate a column to have non_dq and delete total 
us_data_wide_DQ_BLWH <- us_data_attempts_BLWH %>% 
  mutate(non_dq = exit_total - attempts_to_contact_unsuccessful)

us_data_wide_DQ_BLWH_nototal <- us_data_wide_DQ_BLWH %>% 
  select(-exit_total)
```

```{r}
#Per chatGPT. The columns and rows switched...? 
us_dq_BLWH_matrix <- matrix( 
  c(56155, 359718, 99922, 1572263), 
  nrow = 2, 
  dimnames = list(
    c("attempts_to_contact_unsuccessful", "Other"), 
    c("Black", "White")
  ))

```

```{r}
# ODDS RATIO SUCCESS 
# oddsratio(us_dq_BLWH_matrix)
```

Cohen's *h* was calculated to evaluate the effect size of the analysis**.** The result indicated a small to medium effect size, *h* = 0.259. However, even though effect size shows the magnitude of the difference, it is not necessarily considered to be a direct indication of the importance of the findings (Morgan et al., 2020).

```{r}
# Cohen's h prep 

# black_unsuccessful <- 56155
# black_total <- 359718
# white_unsuccessful <- 99922
# white_total <- 1572263
```

```{r}
# Correct cohen's h (-.0.259)
# cohenH(df, observation = "column")
# p1 <- 56155 / (56155 + 359718)
# p1
# p2 <- 99922 / (99922 + 1572263)
# p2
# h <- 2 * (asin(sqrt(p2)) - asin(sqrt(p1)))
# h
```

```{r}
# Cameron helped me make sure

# h <- ES.h(p1, p2)
# h

# pwr.p.test(h = h, n = (black_total + white_total))
```

```{r}
# Another way to get cohen's H, can have NEGATIVE COHEN'S H
# We explored column vs row, but column should be the one we should use, so h = -.259
# library(rcompanion)

# cohenH(us_dq_BLWH_matrix, observation = "column", verbose = TRUE)

# h <- ES.h()
```

```{r}
# CITE ALL THE PACKAGES I USE 
# citation("rcompanion")
```

\newpage

```{r}
cite_packages(output = "paragraph", out.dir = tempdir())
```
